{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0951f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../input/'\n",
    "OUTPUT_DIR = '../output/'\n",
    "IMAGE_DIR = '../image/'\n",
    "SUBMISSION_ID_COLUMN = 'PassengerId'\n",
    "SUBMISSION_OUTPUT_COLUMN = 'Transported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "df = pd.read_csv(f\"{INPUT_DIR}train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256fd23",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f721ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide cabin into three columns\n",
    "# df['cabin_1'] = df['cabin'].astype(str).str.split('/')[0]\n",
    "# df['cabin_2'] = df['cabin'].astype(str).str.split('/')[1]\n",
    "# df['cabin_3'] = df['cabin'].astype(str).str.split('/')[2]\n",
    "# df\n",
    "# cabin_df = df.loc[df['cabin'].notna()]\n",
    "# df[['cabin_1', 'cabin_2', 'cabin_3']] = df['cabin'].astype(str).str.split('/', n=2, expand=True)\n",
    "# cabin_df['cabin_2'] = cabin_df['cabin'].astype(str).str.split('/')[1]\n",
    "# cabin_df['cabin_3'] = cabin_df['cabin'].astype(str).str.split('/')[2]\n",
    "# df['cabin_1'].value_counts() # no null\n",
    "# df['cabin_2'].loc[df['cabin_2'].notna()].astype(int).mean() # 109 null, set to mean() --> 600\n",
    "# df['cabin_3'].isna().sum() # 199, all S or P, set to na\n",
    "# df['cabin_1'].isna().sum() # 0 \n",
    "# df['age'].value_counts()\n",
    "# df['age'].isna().sum() # 182 null, set to na\n",
    "# df['age'][df['age'].notna()].median() # 27.0\n",
    "# df['vip'].isna().sum() # 203\n",
    "# df['vip'].value_counts()\n",
    "# df['vip'] = df['vip'].astype(bool)\n",
    "# values = {'vip': pd.NA}\n",
    "# df.fillna(value=values, inplace=True)\n",
    "# df['vip'].isna().sum()\n",
    "# df['roomservice'].value_counts()\n",
    "# # groupby syntax: df.groupby(['col1','col2']).size(), df.groupby(['Name', 'Fruit'])['Number'].sum() \n",
    "# df.groupby(['roomservice'])['roomservice'].count() # works! 0.0 is highest so that can be value for fillna()\n",
    "# df.groupby(['foodcourt'])['foodcourt'].count() # 0.0 highest use as fillna()\n",
    "# df.groupby(['shoppingmall'])['shoppingmall'].count() # 0.0 highest use as fillna()\n",
    "# df.groupby(['spa'])['spa'].count() # 0.0 highest use as fillna()\n",
    "# df.groupby(['vrdeck'])['vrdeck'].count()  # 0.0 highest use as fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d433ea",
   "metadata": {},
   "source": [
    "### Helper method to clean up, encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66724099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # convert columns to lowercase for convenience\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # drop columns not required\n",
    "    cols_to_drop = [\"passengerid\", \"name\"]\n",
    "    for col in cols_to_drop:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "    # split cabin columns into 3 columns\n",
    "    df[['cabin_1', 'cabin_2', 'cabin_3']] = df['cabin'].astype(str).str.split('/', n=2, expand=True)\n",
    "    df.drop('cabin', axis=1, inplace=True)\n",
    "    \n",
    "    # convert boolean types from object\n",
    "    df['cryosleep'] = df['cryosleep'].astype(bool)\n",
    "    df['vip'] = df['vip'].astype(bool)\n",
    "    df['cabin_2'] = df['vip'].astype(bool)\n",
    "    \n",
    "    # fill null values\n",
    "    fill_values = {'homeplanet': 'na', \n",
    "                   'cryosleep': pd.NA, \n",
    "                   'cabin_1': 'na',\n",
    "                   'cabin_2': -1, \n",
    "                   'cabin_3': 'na', \n",
    "                   'destination': 'na',\n",
    "                   'age': df['age'][df['age'].notna()].median(),\n",
    "                   'vip': pd.NA,\n",
    "                   'roomservice': 0.0,\n",
    "                   'foodcourt': 0.0,\n",
    "                   'shoppingmall': 0.0,\n",
    "                   'spa': 0.0,\n",
    "                   'vrdeck': 0.0         \n",
    "                  }\n",
    "    df.fillna(value=fill_values, inplace=True)\n",
    "    \n",
    "    # convert ojects to category\n",
    "    cols_to_convert = ['homeplanet', 'destination', 'cabin_1', 'cabin_3']\n",
    "    for col in cols_to_convert:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = cleanup(df)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21741a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import get_dummies\n",
    "\n",
    "def one_hot_encoding(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.get_dummies(df, columns=['homeplanet', 'destination', 'cabin_1', 'cabin_3'], \n",
    "               prefix=['homeplanet', 'destination', 'cabin_1', 'cabin_3'])\n",
    "df = one_hot_encoding(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(df: pd.DataFrame, info: str) -> None:\n",
    "    df.to_csv(f\"{OUTPUT_DIR}{info}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9966b08",
   "metadata": {},
   "source": [
    "### Train and see result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d24150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['transported'])\n",
    "y = df['transported']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=randint(1, 100))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# uncomment to run the desired model in the following list\n",
    "models = [\n",
    "    \"DecisionTreeClassifier(max_depth=3, random_state=randint(1, 100))\",\n",
    "    \"DecisionTreeClassifier(max_depth=10, random_state=randint(1, 100))\",\n",
    "    \"RandomForestClassifier(n_estimators=100)\",\n",
    "    \"SGDClassifier(max_iter=1000, tol=1e-3, random_state=randint(1, 100))\"\n",
    "]\n",
    "\n",
    "# Load test data\n",
    "final_test_raw = pd.read_csv(f\"{INPUT_DIR}test.csv\")\n",
    "final_test_df = pd.read_csv(f\"{INPUT_DIR}test.csv\")\n",
    "final_test_input = cleanup(final_test_df)\n",
    "final_test_input = one_hot_encoding(final_test_input)\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.split(\"(\")[0]\n",
    "    print(f\"********** {model_name} **********\")\n",
    "\n",
    "    classifier = eval(model)\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"classifier\", classifier)]\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # cross validation\n",
    "    print(f\"{model_name} train portion cross_val_score accuracy: \\n{cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')}\")\n",
    "\n",
    "    # accuracy with test portion\n",
    "    y_pred = clf.predict(X_test)\n",
    "    n_correct = sum(y_pred == y_test)\n",
    "    print(f\"{model_name} test portion accuracy: {n_correct/len(y_pred)}\")\n",
    "\n",
    "\n",
    "    # Precision and Recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"{model_name} test portion precision: {precision}\")\n",
    "    print(f\"{model_name} test portion recall: {recall}\")\n",
    "    print(f\"{model_name} test portion f1_score: {f1_score}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    y_cf = cross_val_predict(clf, X_train, y_train, cv=3)\n",
    "    print(f\"{model_name} train portion confusion_matrix: {confusion_matrix(y_train, y_cf)}\")\n",
    "\n",
    "    # Run on submission test data and save result\n",
    "    final_test_prediction = clf.predict(final_test_input)\n",
    "    final_test_prediction = pd.DataFrame(final_test_prediction, columns=[SUBMISSION_OUTPUT_COLUMN])\n",
    "    output_df = pd.concat([final_test_raw[SUBMISSION_ID_COLUMN], final_test_prediction[SUBMISSION_OUTPUT_COLUMN]], axis=1) \n",
    "    write_output(output_df, f\"{model_name}_{f1_score}\")\n",
    "final_test_raw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c77dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
